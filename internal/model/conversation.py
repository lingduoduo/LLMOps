#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@File    : conversation.py
"""
from sqlalchemy import (
    Column,
    UUID,
    String,
    Text,
    Integer,
    DateTime,
    Boolean,
    Numeric,
    Float,
    text,
    PrimaryKeyConstraint, func, asc,
)
from sqlalchemy.dialects.postgresql import JSONB

from internal.extension.database_extension import db


class Conversation(db.Model):
    """Conversation model"""
    __tablename__ = "conversation"
    __table_args__ = (
        PrimaryKeyConstraint("id", name="pk_conversation_id"),
    )

    id = Column(UUID, nullable=False, server_default=text("uuid_generate_v4()"))
    app_id = Column(UUID, nullable=False)  # Associated application ID
    name = Column(String(255), nullable=False, server_default=text("''::character varying"))  # Conversation name
    summary = Column(Text, nullable=False, server_default=text("''::text"))  # Conversation summary / long-term memory
    is_pinned = Column(Boolean, nullable=False, server_default=text("false"))  # Whether the conversation is pinned
    is_deleted = Column(Boolean, nullable=False,
                        server_default=text("false"))  # Whether the conversation is soft-deleted
    invoke_from = Column(String(255), nullable=False, server_default=text("''::character varying"))  # Invocation source
    created_by = Column(
        UUID,
        nullable=True,
    )  # Conversation creator. Depending on invoke_from, this may be an account ID (web_app/debugger) or end-user ID (service_api).
    updated_at = Column(
        DateTime,
        nullable=False,
        server_default=text('CURRENT_TIMESTAMP(0)'),
        server_onupdate=text('CURRENT_TIMESTAMP(0)'),
    )
    created_at = Column(DateTime, nullable=False, server_default=text('CURRENT_TIMESTAMP(0)'))

    @property
    def is_new(self) -> bool:
        """Read-only property to determine whether this conversation is newly created"""
        message_count = db.session.query(func.count(Message.id)).filter(
            Message.conversation_id == self.id,
        ).scalar()

        return False if message_count > 1 else True


class Message(db.Model):
    """Message model"""
    __tablename__ = "message"
    __table_args__ = (
        PrimaryKeyConstraint("id", name="pk_message_id"),
    )

    id = Column(UUID, nullable=False, server_default=text("uuid_generate_v4()"))

    # Message associations
    app_id = Column(UUID, nullable=False)  # Associated application ID
    conversation_id = Column(UUID, nullable=False)  # Associated conversation ID
    invoke_from = Column(
        String(255),
        nullable=False,
        server_default=text("''::character varying"),
    )  # Invocation source, including service_api, web_app, debugger, etc.
    created_by = Column(UUID, nullable=False)  # Message creator; may be an LLMOps user or an open API end-user

    # Original question associated with the message
    query = Column(Text, nullable=False, server_default=text("''::text"))  # User's original query
    message = Column(JSONB, nullable=False, server_default=text("'[]'::jsonb"))  # Message list that produced the answer
    message_token_count = Column(Integer, nullable=False,
                                 server_default=text("0"))  # Total token count for the message list
    message_unit_price = Column(Numeric(10, 7), nullable=False, server_default=text("0.0"))  # Unit price for messages
    message_price_unit = Column(Numeric(10, 4), nullable=False, server_default=text("0.0"))  # Price unit for messages

    # Answer information associated with the message
    answer = Column(Text, nullable=False, server_default=text("''::text"))  # Answer generated by the Agent
    answer_token_count = Column(Integer, nullable=False, server_default=text("0"))  # Token count of the answer
    answer_unit_price = Column(Numeric(10, 7), nullable=False, server_default=text("0.0"))  # Token unit price
    answer_price_unit = Column(Numeric(10, 4), nullable=False, server_default=text("0.0"))  # Token price unit

    # Message-related statistics
    latency = Column(Float, nullable=False, server_default=text("0.0"))  # Total latency for this message
    is_deleted = Column(Boolean, nullable=False, server_default=text("false"))  # Soft delete flag
    status = Column(String(255), nullable=False,
                    server_default=text("''::character varying"))  # Message status: normal, error, stopped, etc.
    error = Column(Text, nullable=False, server_default=text("''::text"))  # Error details, if any
    total_token_count = Column(Integer, nullable=False,
                               server_default=text("0"))  # Total tokens consumed, including step-level usage
    total_price = Column(Numeric(10, 7), nullable=False,
                         server_default=text("0.0"))  # Total cost, including step-level usage

    # Time-related fields
    updated_at = Column(
        DateTime,
        nullable=False,
        server_default=text('CURRENT_TIMESTAMP(0)'),
        server_onupdate=text('CURRENT_TIMESTAMP(0)'),
    )
    created_at = Column(DateTime, nullable=False, server_default=text('CURRENT_TIMESTAMP(0)'))

    @property
    def agent_thoughts(self) -> list["MessageAgentThought"]:
        """Read-only property that returns the list of agent reasoning steps for this message"""
        return db.session.query(MessageAgentThought).filter(
            MessageAgentThought.message_id == self.id,
        ).order_by(asc("position")).all()


class MessageAgentThought(db.Model):
    """Agent message reasoning model, used to record steps when the Agent generates the final answer"""
    __tablename__ = "message_agent_thought"
    __table_args__ = (
        PrimaryKeyConstraint("id", name="pk_message_agent_thought_id"),
    )

    id = Column(UUID, nullable=False, server_default=text("uuid_generate_v4()"))

    # Associations for the reasoning step
    app_id = Column(UUID, nullable=False)  # Associated application ID
    conversation_id = Column(UUID, nullable=False)  # Associated conversation ID
    message_id = Column(UUID, nullable=False)  # Associated message ID
    invoke_from = Column(
        String(255),
        nullable=False,
        server_default=text("''::character varying"),
    )  # Invocation source, including service_api, web_app, debugger, etc.
    created_by = Column(UUID, nullable=False)  # Creator; may be an LLMOps user or an open API end-user

    # Position of this step within the message
    position = Column(Integer, nullable=False, server_default=text("0"))  # Position of this reasoning/observation step

    # Reasoning and observation. Reasoning stores LLM-generated messages; observation stores non-LLM messages.
    event = Column(String(255), nullable=False, server_default=text("''::character varying"))  # Event name
    thought = Column(Text, nullable=False, server_default=text("''::text"))  # Reasoning content (LLM-generated)
    observation = Column(Text, nullable=False,
                         server_default=text("''::text"))  # Observation content (KB, tools, etc., for LLM to observe)

    # Tool-related information: includes tool name and input, recorded when tools are invoked
    tool = Column(Text, nullable=False, server_default=text("''::text"))  # Tool name being invoked
    tool_input = Column(JSONB, nullable=False,
                        server_default=text("'{}'::jsonb"))  # Input to the tool from the LLM; empty dict if none

    # Messages used in this reasoning/observation step (prompt messages)
    message = Column(JSONB, nullable=False, server_default=text("'[]'::jsonb"))  # Prompt messages used in this step
    message_token_count = Column(Integer, nullable=False, server_default=text("0"))  # Tokens consumed for messages
    message_unit_price = Column(Numeric(10, 7), nullable=False,
                                server_default=text("0.0"))  # Unit price (CNY) for message tokens
    message_price_unit = Column(
        Numeric(10, 4),
        nullable=False,
        server_default=text("0"),
    )  # Price unit; value 1000 means price per 1000 tokens

    # LLM-generated content for this step
    answer = Column(Text, nullable=False,
                    server_default=text("''::text"))  # LLM-generated answer content; same as thought
    answer_token_count = Column(Integer, nullable=False,
                                server_default=text("0"))  # Tokens consumed for the generated answer
    answer_unit_price = Column(Numeric(10, 7), nullable=False,
                               server_default=text("0.0"))  # Unit price (CNY) for answer tokens
    answer_price_unit = Column(
        Numeric(10, 4),
        nullable=False,
        server_default=text("0.0"),
    )  # Price unit; value 1000 means price per 1000 tokens

    # Aggregate statistics for this reasoning/observation step
    total_token_count = Column(Integer, nullable=False, server_default=text("0"))  # Total tokens consumed in this step
    total_price = Column(Numeric(10, 7), nullable=False, server_default=text("0.0"))  # Total cost in this step
    latency = Column(Float, nullable=False, server_default=text("0.0"))  # Latency for this reasoning/observation step

    # Time-related fields
    updated_at = Column(
        DateTime,
        nullable=False,
        server_default=text('CURRENT_TIMESTAMP(0)'),
        server_onupdate=text('CURRENT_TIMESTAMP(0)'),
    )  # Updated time
    created_at = Column(DateTime, nullable=False, server_default=text('CURRENT_TIMESTAMP(0)'))  # Created time
